{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87c06e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8861adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8ce52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv data\n",
    "path = os.path.join(os.path.dirname(os.getcwd()), 'data', 'spam_processed.csv')\n",
    "df = pd.read_csv(path)\n",
    "print(\"Data imported successfully.\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548f8387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the data\n",
    "print(f\"Shape of the data: {df.shape}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# check for missing values\n",
    "print(df.info())\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# check for class / category distribution\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d926b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "print(\"Number of duplicate rows:\", df.duplicated().sum())\n",
    "\n",
    "print(\"Shape before  removing duplicates:\", df.shape)\n",
    "\n",
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(\"Shape after removing duplicates:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1304931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first of all we will do some basic text preprocessing to clean the textual data \n",
    "# and make it suitable for feature extraction and model training. \n",
    "# This will include steps like:\n",
    "\n",
    "# Lowercase all text\n",
    "df['Message'] = df['Message'].str.lower()\n",
    "\n",
    "# Remove punctuation\n",
    "df['Message'] = df['Message'].str.replace(r'\\W', ' ', regex=True)\n",
    "\n",
    "#  Remove numbers\n",
    "df['Message'] = df['Message'].str.replace(r'\\d', '', regex=True)\n",
    "\n",
    "#  Strip extra spaces\n",
    "df['Message'] = df['Message'].str.strip()\n",
    "\n",
    "\n",
    "\n",
    "#  note we have removed punctuation and numbers from the text, which can help reduce noise in the data.\n",
    "# also it will also help to filter duplicate message which only differ in case, punctuation or numbers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca0436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# again check for duplicates after text preprocessing\n",
    "print(\"Number of duplicate rows after text preprocessing:\", df.duplicated().sum())\n",
    "print(\"Shape before removing duplicates:\", df.shape)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(\"Shape after removing duplicates:\", df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5284c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check preprocessed data\n",
    "print(df.head())\n",
    "print(\"-\" * 50)\n",
    "print(\"spam count vs ham count:\")\n",
    "print(df[\"Category\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6027a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed dataset\n",
    "df.to_csv('../data/spam_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2702cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed data for next steps\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from src.data_preprocessing import load_data\n",
    "\n",
    "processed_csv_path = os.path.join((os.path.dirname(os.getcwd())), 'data', 'spam_processed.csv') \n",
    "#  processed_csv_path  = \"../data/spam_processed.csv\"\n",
    "\n",
    "df = load_data(processed_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e13f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model using the preprocessed data\n",
    "from train import train_model\n",
    "\n",
    "train_model(processed_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict new emails using the trained model\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# add repo root directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from src.model import load_model_and_vectorizer, predict_email\n",
    "\n",
    "# Load model and vectorizer\n",
    "model_name = \"spam_classifier.pkl\"\n",
    "vectorizer_name = \"vectorizer.pkl\"\n",
    "model, vectorizer = load_model_and_vectorizer(model_filename=model_name, vectorizer_filename=vectorizer_name)\n",
    "\n",
    "# Predict new emails\n",
    "emails = [\n",
    "    \"Meeting rescheduled to 3 PM tomorrow. Please confirm your availability.\",\n",
    "    \"You have won a free lottery! Click here to claim your prize.\",\n",
    "]\n",
    "\n",
    "for email in emails:\n",
    "    result = predict_email(email, model, vectorizer)\n",
    "    print(f\"Email: {email}\\nPrediction: {result}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
